{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Sourcing Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('data/ramen-ratings.csv', mode='r') as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    print(csv_reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://www.metaweather.com/api/location/search/?query=london\"\n",
    "response = requests.get(url).json()\n",
    "city = response[0]\n",
    "print(f\"{city['title']}: {city['woeid']} ({city['latt_long']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with params - example, code doesn't run\n",
    "\n",
    "url = \"https://someurl.com/search?query=\"\n",
    "params = {\n",
    "    \"_apikey\" : \"xxx\",\n",
    "    \"url\" : \"https://someurl.com/search?sortby=Price_LH&per_page=96&size=1%2C12&page=35\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beautiful Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "url = \"https://recipes.lewagon.com/?search[query]=carrot\"\n",
    "response = requests.get(url).text\n",
    "soup = BeautifulSoup(response, \"html.parser\")\n",
    "\n",
    "#for recipe in soup.find_all('p', class_= 'recipe-name'):\n",
    "#    print(recipe.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scraping - Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes = []\n",
    "for recipe in soup.find_all(\"div\", class_ =\"recipe my-3\"):\n",
    "    name = recipe.find(\"p\", class_ = \"text-dark text-truncate w-100 font-weight-bold mb-0 recipe-name\").string\n",
    "    difficulty = recipe.find(\"span\", class_=\"recipe-difficulty\").string\n",
    "    prep_time = recipe.find(\"span\", class_ = \"recipe-cooktime\"). string\n",
    "    recipes.append({'name': name, 'difficulty': difficulty, 'prep_time': prep_time})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scraping - Navigate Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.title\n",
    "# <title>The Dormouse's story</title>\n",
    "\n",
    "soup.title.name\n",
    "# u'title'\n",
    "\n",
    "soup.title.string\n",
    "# u'The Dormouse's story'\n",
    "\n",
    "soup.title.parent.name\n",
    "# u'head'\n",
    "\n",
    "soup.p\n",
    "# <p class=\"title\"><b>The Dormouse's story</b></p>\n",
    "\n",
    "soup.p['class']\n",
    "# u'title'\n",
    "\n",
    "soup.a\n",
    "# <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>\n",
    "\n",
    "soup.find_all('a')\n",
    "# [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n",
    "\n",
    "soup.find(id=\"link3\")\n",
    "# <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Scraping - Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import chromedriver_binary\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as ec\n",
    "\n",
    "def launchBrowser():\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(\"https://recipes.lewagon.com/recipes/advanced\")\n",
    "    return driver\n",
    "\n",
    "\n",
    "driver = launchBrowser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_input = driver.find_element_by_id(\n",
    "    'search_query')  #find_element_by_id will be deprecated soon\n",
    "search_input.send_keys('chocolate')\n",
    "search_input.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wait = WebDriverWait(driver, 15)\n",
    "wait.until(ec.visibility_of_element_located(\n",
    "    (By.XPATH, \"//div[@id='recipes']\")))\n",
    "\n",
    "recipe_urls = []\n",
    "cards = driver.find_elements_by_xpath(\"//div[@class='recipe my-3']\")\n",
    "print(f\"Found {len(cards)} results on the page\")\n",
    "\n",
    "for card in cards:\n",
    "    url = card.get_attribute('data-href')\n",
    "    recipe_urls.append(url)\n",
    "\n",
    "recipes = []\n",
    "for url in recipe_urls:\n",
    "    print(f\"Navigating to {url}\")\n",
    "    driver.get(url)\n",
    "    wait.until(\n",
    "        ec.visibility_of_element_located(\n",
    "            (By.XPATH,\n",
    "             \"//div[@class='p-3 border bg-white rounded-lg recipe-container']\"\n",
    "             )))\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    name = soup.find('h2').string.strip()\n",
    "    cooktime = soup.find('span', class_='recipe-cooktime').text.strip()\n",
    "    difficulty = soup.find('span', class_='recipe-difficulty').text.strip()\n",
    "    price = soup.find('small',\n",
    "                      class_='recipe-price').attrs.get('data-price').strip()\n",
    "    description = soup.find('p', class_='recipe-description').text.strip()\n",
    "    recipes.append({\n",
    "        'name': name,\n",
    "        'cooktime': cooktime,\n",
    "        'difficulty': difficulty,\n",
    "        'price': price,\n",
    "        'description': description\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
